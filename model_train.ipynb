{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpaooKC_KtN0",
        "outputId": "2eef7e4c-f86e-4a91-e5af-9c2211e2d4e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 300 images belonging to 3 classes.\n",
            "Found 60 images belonging to 3 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 176s 17s/step - loss: 1.5969 - accuracy: 0.5933 - val_loss: 0.2915 - val_accuracy: 0.9167\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.4841 - accuracy: 0.8567 - val_loss: 0.2070 - val_accuracy: 0.9333\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.2039 - accuracy: 0.9367 - val_loss: 0.0307 - val_accuracy: 0.9833\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0927 - accuracy: 0.9700 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 23s 2s/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.0499 - accuracy: 0.9833 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0633 - accuracy: 0.9800 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.0148 - accuracy: 0.9933 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.0208 - accuracy: 0.9900 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "1/2 [==============>...............] - ETA: 2s - loss: 0.0011 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the path to your image dataset\n",
        "data_dir = '/content/drive/MyDrive/fulhaus/Dataset_refined'\n",
        "\n",
        "# Define the number of classes in your custom dataset\n",
        "num_classes = 3\n",
        "\n",
        "# Define the input size of the images for the model\n",
        "input_size = (224, 224)\n",
        "\n",
        "# Define the batch size and number of epochs for training\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Define the ratio of images to use for validation\n",
        "validation_split = 0.2\n",
        "\n",
        "# Create a list of all the image filenames in the dataset directory\n",
        "filenames = os.listdir(data_dir)\n",
        "\n",
        "# Shuffle the list of filenames\n",
        "random.shuffle(filenames)\n",
        "\n",
        "# Calculate the number of images to use for validation\n",
        "num_validation = int(len(filenames) * validation_split)\n",
        "\n",
        "# Split the filenames into training and validation sets\n",
        "train_filenames = filenames[num_validation:]\n",
        "valid_filenames = filenames[:num_validation]\n",
        "\n",
        "# Define the data augmentation configuration for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Define the data augmentation configuration for validation data\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "# Generate training data batches\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'train'),\n",
        "    target_size=input_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Generate validation data batches\n",
        "valid_data = valid_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'test'),\n",
        "    target_size=input_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load the pre-trained ResNet50 model with ImageNet weights\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_size+(3,))\n",
        "\n",
        "# Add custom classification layers on top of the pre-trained model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Define the final classification model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the pre-trained layers of the model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(train_data, epochs=epochs, validation_data=valid_data)\n",
        "\n",
        "# Save the trained model to a file\n",
        "model.save('/content/drive/MyDrive/fulhaus/resnet.h5')\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "score = model.evaluate(valid_data)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}